# ====== ç¬¬ 1 æ­¥ï¼šåŠ è½½çŸ¥è¯† ======

from langchain_core.documents import Document

raw_knowledege = """
LangChain æ˜¯ä¸€ä¸ªç”¨äºå¼€å‘å¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„æ¡†æ¶ã€‚
å®ƒæ”¯æŒé“¾å¼è°ƒç”¨ï¼ˆChainsï¼‰ã€æ™ºèƒ½ä»£ç†ï¼ˆAgentsï¼‰ã€é•¿æœŸè®°å¿†ï¼ˆMemoryï¼‰ç­‰åŠŸèƒ½ã€‚
RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯ä¸€ç§ç»“åˆå¤–éƒ¨çŸ¥è¯†åº“ä¸è¯­è¨€æ¨¡å‹çš„æŠ€æœ¯ã€‚
é€šè¿‡å…ˆæ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œå†è®©å¤§æ¨¡å‹åŸºäºè¿™äº›æ–‡æ¡£ç”Ÿæˆç­”æ¡ˆï¼Œå¯ä»¥æ˜¾è‘—æé«˜å›ç­”å‡†ç¡®æ€§ã€‚
Chroma æ˜¯ä¸€ä¸ªè½»é‡çº§å‘é‡æ•°æ®åº“ï¼Œé€‚åˆåµŒå…¥åˆ° Python åº”ç”¨ä¸­ã€‚
"""
docs = [Document(page_content = raw_knowledege)]
print("çŸ¥è¯†åŠ è½½å®Œæˆï¼å…±ä¸€ä¸ªæ–‡æ¡£")

# ====== ç¬¬ 2æ­¥ï¼šåˆ‡åˆ†æ–‡æœ¬ ======
from langchain_text_splitters import  RecursiveCharacterTextSplitter
# åˆ›å»ºåˆ‡åˆ†å™¨ï¼šæŒ‰å­—ç¬¦é€’å½’åˆ‡åˆ†ï¼ˆä¼˜å…ˆæŒ‰ "\n\n" â†’ "\n" â†’ " "ï¼‰
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 100,# æ¯å—æœ€å¤š 100 ä¸ªå­—ç¬¦
    chunk_overlap = 20 # ç›¸é‚»å—é‡å  20 ä¸ªå­—ç¬¦ï¼ˆé¿å…æ–­å¥ï¼‰
)
#æ‰§è¡Œåˆ‡åˆ†
chunks = text_splitter.split_documents(docs)
print("æ–‡æœ¬åˆ‡åˆ†ä¸º{}ä¸ªå—".format(len(chunks)))

#æ‰“å°æ¯å—å†…å®¹
for i,chunk in enumerate(chunks):
    print(f"[å— {i + 1}] {repr(chunk.page_content)}")

# ====== ç¬¬ 3æ­¥ï¼šå‘é‡åŒ–+ å­˜å…¥æ•°æ®åº“
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_huggingface import HuggingFaceEmbeddings
from  langchain_chroma import  Chroma
print("æ­£åœ¨å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼ˆé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼‰")

#åˆ›å»ºEmbedding æ¨¡å‹ï¼ˆæœ¬åœ°è¿è¡Œï¼Œæ— éœ€ç½‘ç»œï¼‰
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

#åˆ›å»º chromaå‘é‡æ•°æ®åº“ï¼Œå¹¶æŠŠchunkså­˜è¿›å»
vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings
)
print("å‘é‡æ•°æ®åº“åˆ›å»ºæˆåŠŸ")

# ====== ç¬¬ 4æ­¥,æ£€ç´¢æµ‹è¯•
#åˆ›å»ºæ£€ç´¢å™¨ï¼Œæ¯æ¬¡è¿”å›æœ€ç›¸ä¼¼çš„2ä¸ªæ–‡æœ¬å—
retriever = vectorstore.as_retriever(search_kwargs={"k":2})

#ç”¨æˆ·æé—®
question = "ä»€ä¹ˆæ˜¯RAG"

#æ‰§è¡Œæœç´¢
results = retriever.invoke(question)

#è¾“å‡ºç»“æœ
print("ç”¨æˆ·é—®{}?".format(question))
print("æ£€ç´¢åˆ°çš„ç›¸å…³çš„å†…å®¹ï¼š")
for  i,doc in enumerate(results):
    print(f"[{i + 1}] {doc.page_content.strip()}")

# ====== ç¬¬ 5 æ­¥ï¼šäº¤äº’å¼é—®ç­” ======
print("\nğŸ’¬ ç°åœ¨è¿›å…¥é—®ç­”æ¨¡å¼ï¼è¾“å…¥ 'é€€å‡º' ç»“æŸç¨‹åºã€‚")

while True:
    question = input("\nâ“ è¯·è¾“å…¥ä½ çš„é—®é¢˜: ").strip()
    if question in ["é€€å‡º", "exit", "quit"]:
        print("ğŸ‘‹ å†è§ï¼")
        break
    if not question:
        continue

    results = retriever.invoke(question)
    print("ğŸ“š æœ€ç›¸å…³çš„çŸ¥è¯†:")
    for i, doc in enumerate(results):
        print(f"[{i + 1}] {doc.page_content.strip()}")